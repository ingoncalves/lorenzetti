#!/usr/bin/env python3
import argparse
import sys
from pathlib import Path
from joblib import Parallel, delayed

from CaloCellBuilder import CaloCellBuilder
from ATLAS import ATLASConstruction as ATLAS
from GaugiKernel import LoggingLevel, get_argparser_formatter
from GaugiKernel import ComponentAccumulator
from RootStreamBuilder import RootStreamHITReader, recordable
from RootStreamBuilder import RootStreamESDMaker


def parse_args():
    # create the top-level parser
    parser = argparse.ArgumentParser(
        description='',
        formatter_class=get_argparser_formatter(),
        add_help=False)

    parser.add_argument('-i', '--input-file', action='store',
                        dest='input_file', required=False,
                        help="The event input file generated by the"
                        " Pythia event generator.")

    parser.add_argument('-o', '--output-file', action='store',
                        dest='output_file', required=False,
                        help="The reconstructed event file generated"
                        " by lzt/geant4 framework.")

    parser.add_argument('--nov', '--number-of-events', action='store',
                        dest='number_of_events', required=False,
                        type=int, default=-1,
                        help="The number of events to apply the"
                        " reconstruction.")

    parser.add_argument('-l', '--output-level', action='store',
                        dest='output_level', required=False,
                        type=str, default='INFO',
                        help="The output level messenger.")

    parser.add_argument('-c', '--command', action='store',
                        dest='command', required=False, default="''",
                        help="The preexec command")

    parser.add_argument('-nt', '--number-of-threads', action='store',
                        dest='number_of_threads', required=False,
                        type=int, default=1,
                        help="The number of threads")

    if len(sys.argv) == 1:
        parser.print_help()
        sys.exit(1)

    args = parser.parse_args()
    args.input_file = Path(args.input_file)
    if not args.input_file.exists():
        raise FileNotFoundError(f"Input file {args.input_file} not found.")
    if args.input_file.is_dir():
        args.input_file = args.input_file.glob("*.root")
    else:
        args.input_file = [args.input_file]
    return args


def main(logging_level: str,
         input_file: str | Path,
         output_file: str | Path,
         command: str,
         number_of_events: int):

    if isinstance(input_file, Path):
        input_file = str(input_file)
    if isinstance(output_file, Path):
        output_file = str(output_file)

    outputLevel = LoggingLevel.toC(logging_level)
    exec(command)

    acc = ComponentAccumulator("ComponentAccumulator", output_file)

    # the reader must be first in sequence
    reader = RootStreamHITReader("HITReader",
                                 InputFile=input_file,
                                 OutputHitsKey=recordable("Hits"),
                                 OutputEventKey=recordable("Events"),
                                 OutputTruthKey=recordable("Particles"),
                                 OutputSeedsKey=recordable("Seeds"),
                                 OutputLevel=outputLevel,
                                 )

    reader.merge(acc)

    # digitalization!

    calorimeter = CaloCellBuilder("CaloCellBuilder", ATLAS(),
                                  HistogramPath="Expert/Cells",
                                  OutputLevel=outputLevel,
                                  InputHitsKey=recordable("Hits"),
                                  OutputCellsKey=recordable("Cells"),
                                  OutputTruthCellsKey=recordable(
        "TruthCells"),
    )
    calorimeter.merge(acc)

    ESD = RootStreamESDMaker("RootStreamESDMaker",
                             InputCellsKey=recordable("Cells"),
                             InputEventKey=recordable("Events"),
                             InputTruthKey=recordable("Particles"),
                             InputSeedsKey=recordable("Seeds"),
                             OutputLevel=outputLevel)
    acc += ESD

    acc.run(number_of_events)


def get_job_params(args):
    splitted_output_filename = args.output_file.split(".")
    for i, input_file in enumerate(args.input_file):
        output_file = splitted_output_filename.copy()
        output_file.insert(-1, str(i))
        output_file = Path('.'.join(output_file))
        if output_file.exists():
            print(f"{i} - Output file {output_file} already exists. Skipping.")
            continue
        yield input_file, output_file


if __name__ == "__main__":
    args = parse_args()
    pool = Parallel(n_jobs=args.number_of_threads)
    pool(delayed(main)(
            logging_level=args.output_level,
            input_file=input_file,
            output_file=output_file,
            command=args.command,
            number_of_events=args.number_of_events
    )
        for input_file, output_file in get_job_params(args))
